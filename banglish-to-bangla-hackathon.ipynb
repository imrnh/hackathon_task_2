{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip3 install datasets\n!pip install git+https://github.com/csebuetnlp/normalizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom normalizer import normalize\nfrom datasets import load_dataset\nfrom tqdm.auto import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:44:58.321408Z","iopub.execute_input":"2024-12-21T15:44:58.321714Z","iopub.status.idle":"2024-12-21T15:44:59.737510Z","shell.execute_reply.started":"2024-12-21T15:44:58.321688Z","shell.execute_reply":"2024-12-21T15:44:59.736488Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Load and Split dataset","metadata":{}},{"cell_type":"code","source":"dataset_url = \"SKNahin/bengali-transliteration-data\"\nmodel_url = \"csebuetnlp/banglat5_banglaparaphrase\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:44:59.739687Z","iopub.execute_input":"2024-12-21T15:44:59.740232Z","iopub.status.idle":"2024-12-21T15:44:59.744552Z","shell.execute_reply.started":"2024-12-21T15:44:59.740201Z","shell.execute_reply":"2024-12-21T15:44:59.743381Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"raw_dataset = load_dataset(dataset_url)\nsplit_dataset = raw_dataset['train'].train_test_split(test_size=0.2)\n\ntrain_dataset = split_dataset['train']\ntest_dataset = split_dataset['test']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:44:59.745808Z","iopub.execute_input":"2024-12-21T15:44:59.746175Z","iopub.status.idle":"2024-12-21T15:45:01.223499Z","shell.execute_reply.started":"2024-12-21T15:44:59.746137Z","shell.execute_reply":"2024-12-21T15:45:01.222431Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/300 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fc58d8ec40440d89bf2d59203ddedd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/333k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21cbf21acf054d9c938e8ad959a8e9fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5006 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0ffbcee53654f18940a1acbb8fa4bd9"}},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Load model and Save weight","metadata":{"execution":{"iopub.status.busy":"2024-12-21T12:53:01.931458Z","iopub.execute_input":"2024-12-21T12:53:01.932061Z","iopub.status.idle":"2024-12-21T12:53:01.936434Z","shell.execute_reply.started":"2024-12-21T12:53:01.932026Z","shell.execute_reply":"2024-12-21T12:53:01.935119Z"}}},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(model_url)\ntokenizer = AutoTokenizer.from_pretrained(model_url, use_fast=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:45:01.224750Z","iopub.execute_input":"2024-12-21T15:45:01.225327Z","iopub.status.idle":"2024-12-21T15:45:08.791705Z","shell.execute_reply.started":"2024-12-21T15:45:01.225296Z","shell.execute_reply":"2024-12-21T15:45:08.790587Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/707 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5598c5f9b3604d19b0d4183ed499a129"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00dfe3d0473e4efb9b84e1ad83c28c19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8c12a4ad51a4076ad0c9732fceb6672"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d367032be3740009d1c356ab76363c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efd160a22f034e5c9520c4e0a8dd9893"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Save the model weights to load later","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), \"model_weights.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:45:14.061010Z","iopub.execute_input":"2024-12-21T15:45:14.061587Z","iopub.status.idle":"2024-12-21T15:45:15.367305Z","shell.execute_reply.started":"2024-12-21T15:45:14.061534Z","shell.execute_reply":"2024-12-21T15:45:15.366310Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Save both dataset as CSV","metadata":{}},{"cell_type":"code","source":"train_dataset.to_csv(\"train.csv\")\ntest_dataset.to_csv(\"test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:45:15.699326Z","iopub.execute_input":"2024-12-21T15:45:15.699737Z","iopub.status.idle":"2024-12-21T15:45:15.800739Z","shell.execute_reply.started":"2024-12-21T15:45:15.699703Z","shell.execute_reply":"2024-12-21T15:45:15.799531Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a1d2da26dd54f5e98eec15cca6bade3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4964e0810a10473f96b55ef10d527476"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"134045"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# PyTorch dataset pipeline building\n\n### <font color=\"orange\">Sentence with more than 256 tokens are truncated.","metadata":{}},{"cell_type":"code","source":"class BanglishToBanglaDataset(Dataset):\n    def __init__(self, data_path, tokenizer):\n        self.data = pd.read_csv(data_path)\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        d = self.data.loc[idx]\n        bn, rm = d['bn'], d['rm']\n\n        bn_t = tokenizer(normalize(bn), return_tensors=\"pt\", padding='max_length', max_length=256, truncation=True).input_ids\n        rm_t = tokenizer(normalize(rm), return_tensors=\"pt\", padding='max_length', max_length=256, truncation=True).input_ids\n\n        return rm_t, bn_t\n        return {\n            \"input_ids\": rm_t,\n            \"attention_mask\": rm_t.attention_mask.squeeze(0),\n            \"labels\": bn_t,\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:46:18.174980Z","iopub.execute_input":"2024-12-21T15:46:18.175400Z","iopub.status.idle":"2024-12-21T15:46:18.182111Z","shell.execute_reply.started":"2024-12-21T15:46:18.175369Z","shell.execute_reply":"2024-12-21T15:46:18.181058Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"dataset = BanglishToBanglaDataset(\"train.csv\", tokenizer)\ndataloader = DataLoader(dataset, batch_size=16, shuffle=True)\ndataloader = tqdm(dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:46:18.992970Z","iopub.execute_input":"2024-12-21T15:46:18.993303Z","iopub.status.idle":"2024-12-21T15:46:19.033631Z","shell.execute_reply.started":"2024-12-21T15:46:18.993277Z","shell.execute_reply":"2024-12-21T15:46:19.032673Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/251 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e628972fbdf4645ab8c56136644ccbf"}},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\nfrom torch.optim import AdamW\nfrom torch.nn import CrossEntropyLoss\n\n# Optimizer\noptimizer = AdamW(model.parameters(), lr=1e-3) \n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Training loop\nepochs = 15\nfor epoch in range(epochs):\n    model.train()\n    loop = tqdm(dataloader, leave=True)\n    for batch in loop:\n        # Move data to device\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        # Forward pass\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n\n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Update progress bar\n        loop.set_description(f\"Epoch {epoch}\")\n        loop.set_postfix(loss=loss.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:46:20.854968Z","iopub.execute_input":"2024-12-21T15:46:20.855315Z"}},"outputs":[],"execution_count":null}]}